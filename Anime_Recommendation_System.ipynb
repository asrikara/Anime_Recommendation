{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db07815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gc\n",
    "\n",
    "# Set device for PyTorch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to free up memory\n",
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Load Data\n",
    "anime = pd.read_csv(\"anime.csv\")\n",
    "ratings = pd.read_csv(\"rating.csv\")\n",
    "\n",
    "# Preprocessing Anime Data\n",
    "anime.genre.fillna(\"NULL\", inplace=True)\n",
    "anime.type.fillna(\"NULL\", inplace=True)\n",
    "anime.rating.fillna(anime.rating.mean(), inplace=True)\n",
    "\n",
    "# Filter out bad anime IDs from the ratings\n",
    "valid_anime_ids = set(anime.anime_id)\n",
    "ratings = ratings[ratings.anime_id.isin(valid_anime_ids)]\n",
    "ratings = ratings[ratings.rating != -1]  # Exclude unrated items (-1)\n",
    "\n",
    "# Feature Engineering on Anime Data\n",
    "anime['genre'] = anime['genre'].apply(lambda x: \" \".join(x.split(\" \")).split(\", \"))\n",
    "genres = list(set(g for sublist in anime['genre'] for g in sublist))\n",
    "for genre in genres:\n",
    "    anime['genre_' + genre] = anime['genre'].apply(lambda x: 1 if genre in x else 0)\n",
    "\n",
    "# One-hot encoding for anime type\n",
    "anime = pd.concat([anime, pd.get_dummies(anime['type'], prefix='type')], axis=1)\n",
    "anime.drop(['genre', 'type', 'episodes', 'name'], axis=1, inplace=True)\n",
    "anime.rename(columns={\"rating\": \"avgRating\"}, inplace=True)\n",
    "\n",
    "# Merging Ratings with Anime Data\n",
    "ratings = pd.merge(ratings, anime, on=\"anime_id\", how=\"left\")\n",
    "ratings.fillna(0, inplace=True)\n",
    "\n",
    "# Preparing Training and Validation Sets\n",
    "train = ratings.sample(frac=0.8, random_state=42)\n",
    "validation = ratings.drop(train.index)\n",
    "\n",
    "# Normalize Numerical Features\n",
    "scalers = {\n",
    "    'avgRating': MinMaxScaler(),\n",
    "    'members': MinMaxScaler()\n",
    "}\n",
    "\n",
    "for feature, scaler in scalers.items():\n",
    "    train[feature] = scaler.fit_transform(train[[feature]])\n",
    "    validation[feature] = scaler.transform(validation[[feature]])\n",
    "\n",
    "# Encode Anime IDs\n",
    "anime_encoder = LabelEncoder()\n",
    "train['anime_id'] = anime_encoder.fit_transform(train['anime_id'])\n",
    "validation['anime_id'] = anime_encoder.transform(validation['anime_id'])\n",
    "\n",
    "# Model Definition\n",
    "class RecommendationNet(nn.Module):\n",
    "    def __init__(self, num_users, num_animes, num_features):\n",
    "        super(RecommendationNet, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, 100)\n",
    "        self.anime_embedding = nn.Embedding(num_animes, 100)\n",
    "        self.fc1 = nn.Linear(200 + num_features, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        user = x[:, 0].long()\n",
    "        anime = x[:, 1].long()\n",
    "        other_features = x[:, 2:]\n",
    "        \n",
    "        user_vec = self.user_embedding(user)\n",
    "        anime_vec = self.anime_embedding(anime)\n",
    "        x = torch.cat((user_vec, anime_vec, other_features), dim=1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Initialize Model, Optimizer, and Loss\n",
    "num_users = ratings['user_id'].nunique()\n",
    "num_animes = len(anime_encoder.classes_)\n",
    "num_features = train.shape[1] - 3  # Exclude 'user_id', 'anime_id', 'rating'\n",
    "\n",
    "model = RecommendationNet(num_users, num_animes, num_features).to(device)\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.001)\n",
    "\n",
    "# Prepare DataLoader\n",
    "def prepare_data_loader(data, batch_size=32):\n",
    "    tensor_data = torch.tensor(data.to_numpy(), dtype=torch.float32)\n",
    "    dataset = TensorDataset(tensor_data)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_loader = prepare_data_loader(train, batch_size=32)\n",
    "val_loader = prepare_data_loader(validation, batch_size=32)\n",
    "\n",
    "# Training Loop with Gradient Accumulation\n",
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs=10, accumulation_steps=4):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for i, (batch,) in enumerate(train_loader):\n",
    "            batch = batch.to(device)\n",
    "            X = batch[:, 1:]\n",
    "            y = batch[:, :1]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(X)\n",
    "            loss = F.mse_loss(predictions, y)\n",
    "            loss = loss / accumulation_steps  # Scale the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient accumulation\n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                clear_memory()  # Free memory after each accumulation step\n",
    "                \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for val_batch, in val_loader:\n",
    "                val_batch = val_batch.to(device)\n",
    "                val_X = val_batch[:, 1:]\n",
    "                val_y = val_batch[:, :1]\n",
    "                val_predictions = model(val_X)\n",
    "                val_loss += F.mse_loss(val_predictions, val_y).item()\n",
    "            \n",
    "            val_loss = np.sqrt(val_loss / len(val_loader))\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss/len(train_loader):.4f}, Validation Error: {val_loss:.4f}\")\n",
    "        clear_memory()\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, optimizer)\n",
    "\n",
    "# Recommendations\n",
    "def recommend_animes(model, user_id, top_n=10):\n",
    "    user_data = production_data[production_data.user_id == user_id].copy()\n",
    "    user_data['anime_id'] = anime_encoder.transform(user_data['anime_id'])\n",
    "    user_tensor = torch.tensor(user_data.to_numpy(), dtype=torch.float32).to(device)\n",
    "    user_tensor[:, 0] = model(user_tensor[:, 1:]).cpu().detach().numpy().reshape(-1)\n",
    "    recommendations = user_data.iloc[user_tensor[:, 0].argsort()[-top_n:][::-1]]\n",
    "    return anime[anime.anime_id.isin(recommendations['anime_id'].tolist())]\n",
    "\n",
    "# Get recommendations for user 1\n",
    "recommended_animes = recommend_animes(model, user_id=1)\n",
    "print(recommended_animes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a11b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9bfec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
